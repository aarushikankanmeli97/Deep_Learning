{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = digits.data\n",
    "Y = digits.target\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(Y)\n",
    "y = np.array(y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = digits.data.shape[1] # Number of neurons in input layer (depends on the number of attributes)\n",
    "n1 = 55 # Number of neurons in first hidden layer\n",
    "n2 = 40 # Number of neurons in second hidden layer\n",
    "n3 = digits.target_names.shape[0] # Number of neurons in output layer (depends on the class labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = (64, 1797)\n",
      "w1 = (55, 64)\n",
      "w2 = (40, 55)\n",
      "w3 = (10, 40)\n"
     ]
    }
   ],
   "source": [
    "w1 = np.random.randn(n1,n0) * 0.01\n",
    "b1 = np.zeros((n1,1))\n",
    "w2 = np.random.randn(n2,n1) * 0.01\n",
    "b2 = np.zeros((n2,1))\n",
    "w3 = np.random.randn(n3,n2) * 0.01\n",
    "b3 = np.zeros((n3,1))\n",
    "#w1[0]\n",
    "X = x.T\n",
    "print('X = ' + str(X.shape))\n",
    "print('w1 = ' + str(w1.shape))\n",
    "print('w2 = ' + str(w2.shape))\n",
    "print('w3 = ' + str(w3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    r = np.maximum(0,z)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward (a_prev,w,b):\n",
    "    z = np.dot(w,a_prev) + b\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(A):\n",
    "        f = np.zeros(A.shape, dtype=int)\n",
    "        f[A>0] = 1    \n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =  6.932181113712988\n",
      "Error =  4.647860702432515\n",
      "Error =  3.47030438825186\n",
      "Error =  3.9832456263769203\n",
      "Error =  3.9457299040456117\n",
      "Error =  3.6224257360436316\n",
      "Error =  3.465217495932778\n",
      "Error =  3.380677825921431\n",
      "Error =  3.3320413608247064\n",
      "Error =  3.302666003616135\n",
      "Error =  3.2842118156216027\n",
      "Error =  3.2722099327565113\n",
      "Error =  3.2640998594919686\n",
      "Error =  3.258283444978791\n",
      "Error =  3.2536784153531064\n",
      "Error =  3.2494288789230446\n",
      "Error =  3.2447044819112247\n",
      "Error =  3.238521865461259\n",
      "Error =  3.229546183788351\n",
      "Error =  3.215835966005566\n",
      "Error =  3.194667424700867\n",
      "Error =  3.162501414526654\n",
      "Error =  3.1158566115511475\n",
      "Error =  3.0536201027491128\n",
      "Error =  2.977691532382437\n",
      "Error =  2.8911687258264114\n",
      "Error =  2.7924137721924334\n",
      "Error =  2.6788583416143283\n",
      "Error =  2.5743331009849566\n",
      "Error =  3.1508419239048067\n",
      "Error =  6.425413226321698\n",
      "Error =  3.3366317126457847\n",
      "Error =  3.3174491169412317\n",
      "Error =  3.301831553161011\n",
      "Error =  3.2896561249495737\n",
      "Error =  3.2797149000111547\n",
      "Error =  3.2715834613899286\n",
      "Error =  3.2654347249911937\n",
      "Error =  3.2605043406033145\n",
      "Error =  3.2565847791103493\n",
      "Error =  3.253127833748882\n",
      "Error =  3.250384844492885\n",
      "Error =  3.247815540531429\n",
      "Error =  3.2451795626026296\n",
      "Error =  3.241722601952065\n",
      "Error =  3.2362596914211292\n",
      "Error =  3.231264295325694\n",
      "Error =  3.22378248273387\n",
      "Error =  3.2119127912312972\n",
      "Error =  3.1970416829156973\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    a = linear_forward(X,w1,b1)\n",
    "    \n",
    "            # Applying the relu function on the output of first hidden layer\n",
    "    a1 = relu(a)\n",
    "    \n",
    "            # Applying forward propogation for second layer\n",
    "    b = linear_forward(a1,w2,b2)\n",
    "    \n",
    "            # Applying the relu function on the output of second hidden layer\n",
    "    a2 = relu(b)\n",
    "    \n",
    "            # Applying forward propogation for third layer\n",
    "    c = linear_forward(a2,w3,b3)\n",
    "    \n",
    "            # Applying the sigmoid function on the output layer\n",
    "    a3 = sigmoid(c)\n",
    "    \n",
    "            # Applying Cost Function\n",
    "    L = np.sum(np.multiply(y, np.log(a3)) + np.multiply((1 - y), np.log(1 - a3)))\n",
    "    L = np.multiply(L,(-1/1797))\n",
    "    print(\"Error = \",L)\n",
    "    \n",
    "    #############################################################################################################\n",
    "    \n",
    "    dz3 = a3 - y\n",
    "    \n",
    "    dw3 = np.dot(dz3,a2.T)\n",
    "    dw3 * (1/1797)\n",
    "    \n",
    "    db3 = np.sum(dz3,axis = 1,keepdims = True)\n",
    "    \n",
    "    # Finding derivatives for second layer\n",
    "    dz2 = np.dot(w3.T,dz3)\n",
    "    d = derivative(b)\n",
    "    dz2 = dz2 * d\n",
    "    dw2 = np.dot(dz2,a1.T)\n",
    "    dw2 * (1/1797)\n",
    "    \n",
    "    db2 = np.sum(dz2,axis = 1,keepdims = True)\n",
    "    \n",
    "    # Finding derivatives for first layer\n",
    "    dz1 = np.dot(w2.T,dz2)\n",
    "    d = derivative(a)\n",
    "    dz1 = dz1 * d\n",
    "    \n",
    "    dw1 = np.dot(dz1,x)\n",
    "    dw1 = dw1 * (1/1797)\n",
    "    \n",
    "    db1 = np.sum(dz1,axis = 1,keepdims = True)\n",
    "    \n",
    "    # Weight and Bias updation\n",
    "    w1 = w1 - (0.001 * dw1)\n",
    "    b1 = b1 - (0.001 * db1)\n",
    "    w2 = w2 - (0.001 * dw2)\n",
    "    b2 = b2 - (0.001 * db2)\n",
    "    w3 = w3 - (0.001 * dw3)\n",
    "    b3 = b3 - (0.001 * db3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
