{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnD_SjciX7O_"
   },
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-4cRGzwX7PA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_data = pd.read_excel(\"Internship_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfuZNnD2X7PP"
   },
   "source": [
    "### Extracting the 'view' columns from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7r9--EDyYpB0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDmNEnpoX7PQ"
   },
   "outputs": [],
   "source": [
    "# Generalising the program by retrieving the 'view' columns from the dataset using '.iloc'\n",
    "views = shoe_data.iloc[:,1:6]\n",
    "views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNQ58D2gX7PT",
    "outputId": "fc33e206-b4d6-42e8-8e34-57db9eeabfb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zipper', 'backstrap', 'slip_on', 'lace_up', 'buckle', 'hook&look'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the unique 'class' values in a variable \n",
    "labels = shoe_data['class'].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uz7GSIh9X7PX"
   },
   "source": [
    "### Creating the main directory and sub-directories automatically based on the class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSUCfZtYX7PY",
    "outputId": "5e74110b-55c5-4e0e-c3cf-827e8f985c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/dru_6/Pictures/shoes/zipper\n",
      "Successfully created the directory /home/dru_6/Pictures/shoes/backstrap\n",
      "Successfully created the directory /home/dru_6/Pictures/shoes/slip_on\n",
      "Successfully created the directory /home/dru_6/Pictures/shoes/lace_up\n",
      "Successfully created the directory /home/dru_6/Pictures/shoes/buckle\n",
      "Successfully created the directory /home/dru_6/Pictures/shoes/hook&look\n"
     ]
    }
   ],
   "source": [
    "# Using 'makedirs' function from 'os' library to create  6 subdirectories bearing the class name. Also using the\n",
    "# 'try-except' method for confirmation/failure of directory creation\n",
    "for sub_dirs in labels:\n",
    "    path = '/home/dru_6/Pictures/shoes/' + sub_dirs\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSerror:\n",
    "        print(\"Creation of the directory %s failed\" % path)\n",
    "    else:  \n",
    "        print (\"Successfully created the directory %s\" % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEoA1U3CX7Pc"
   },
   "source": [
    "### Downloading the images from the URLs using the 'for' loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOv7BmqbX7Pd"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "path = '/home/dru_6/Pictures/shoes/'\n",
    "for sub_dirs in labels:\n",
    "    for images in views:\n",
    "        for urls in (shoe_data[images][shoe_data['class']==sub_dirs]):\n",
    "            URL = str(urls)\n",
    "            #print(URL)\n",
    "            if (URL != 'nan'):\n",
    "                urllib.request.urlretrieve(URL, path + sub_dirs + '/' +str(count) + '.jpg')\n",
    "                count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5RkuRznX7Pg"
   },
   "outputs": [],
   "source": [
    "'''os.getcwd()\n",
    "collection = '/home/dru_6/Pictures/valid/zipper'\n",
    "for i, filename in enumerate(os.listdir(collection)):\n",
    "    os.rename(collection + '/' + filename, collection + '/' + filename + '.jpg')\n",
    "    #filename = filename + \".jpg\"\n",
    "    #print(filename)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HnIe2HFcX7Pj",
    "outputId": "2ff7562d-929d-4e95-fb0f-4067a1ed01d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "GWRxHEarS4Yw",
    "outputId": "0a380ccb-4a41-44f6-c9b2-5c5def69a844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEFhfvq8X7Po"
   },
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSqBn1xwX7Pr"
   },
   "outputs": [],
   "source": [
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Hpnia3ppX7Pu",
    "outputId": "44c4d06a-1adc-4f5d-cafc-38706173cb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7223 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"/content/gdrive/My Drive/train/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jOSmIs6LX7Py",
    "outputId": "aeae556c-1dc2-4741-e031-405df8809506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2685 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=r\"/content/gdrive/My Drive/valid\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRhOm0Y7aFe2"
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "LKA1PIMBX7P-",
    "outputId": "5c6d5912-18e7-4aeb-fb44-92cd117db0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "model =  VGG_16()\n",
    "opt = optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, decay=1e-5/5, amsgrad=False, clipnorm = 1.)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "# serialize model to JSON\n",
    "#print(model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zR5TnHegX7QG"
   },
   "source": [
    "verbose -> By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYZvKuPCgA_f"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1125
    },
    "colab_type": "code",
    "id": "Ij3cS9nJX7QI",
    "outputId": "08d364ba-eb93-4c62-872a-7800b95e6fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "226/226 [==============================] - 2926s 13s/step - loss: 1.7415 - acc: 0.2252 - val_loss: 1.7541 - val_acc: 0.2104\n",
      "Epoch 2/30\n",
      "226/226 [==============================] - 442s 2s/step - loss: 1.6655 - acc: 0.2550 - val_loss: 1.5946 - val_acc: 0.2939\n",
      "Epoch 3/30\n",
      "226/226 [==============================] - 417s 2s/step - loss: 1.5699 - acc: 0.3241 - val_loss: 1.6295 - val_acc: 0.2991\n",
      "Epoch 4/30\n",
      "226/226 [==============================] - 415s 2s/step - loss: 1.5459 - acc: 0.3409 - val_loss: 1.5025 - val_acc: 0.3721\n",
      "Epoch 5/30\n",
      "226/226 [==============================] - 440s 2s/step - loss: 1.4896 - acc: 0.3680 - val_loss: 1.4928 - val_acc: 0.3877\n",
      "Epoch 6/30\n",
      "226/226 [==============================] - 444s 2s/step - loss: 1.4604 - acc: 0.3852 - val_loss: 1.4885 - val_acc: 0.4156\n",
      "Epoch 7/30\n",
      "226/226 [==============================] - 426s 2s/step - loss: 1.4419 - acc: 0.4009 - val_loss: 1.4691 - val_acc: 0.3799\n",
      "Epoch 8/30\n",
      "226/226 [==============================] - 447s 2s/step - loss: 1.3882 - acc: 0.4318 - val_loss: 1.3527 - val_acc: 0.4428\n",
      "Epoch 9/30\n",
      "226/226 [==============================] - 438s 2s/step - loss: 1.3263 - acc: 0.4586 - val_loss: 1.3478 - val_acc: 0.4775\n",
      "Epoch 10/30\n",
      "226/226 [==============================] - 415s 2s/step - loss: 1.2718 - acc: 0.4849 - val_loss: 1.3034 - val_acc: 0.4968\n",
      "Epoch 11/30\n",
      "226/226 [==============================] - 409s 2s/step - loss: 1.2165 - acc: 0.5144 - val_loss: 1.2726 - val_acc: 0.4890\n",
      "Epoch 12/30\n",
      "226/226 [==============================] - 405s 2s/step - loss: 1.1466 - acc: 0.5462 - val_loss: 1.2062 - val_acc: 0.5300\n",
      "Epoch 13/30\n",
      "226/226 [==============================] - 405s 2s/step - loss: 1.1129 - acc: 0.5619 - val_loss: 1.1635 - val_acc: 0.5460\n",
      "Epoch 14/30\n",
      "226/226 [==============================] - 405s 2s/step - loss: 1.0473 - acc: 0.5811 - val_loss: 1.1597 - val_acc: 0.5508\n",
      "Epoch 15/30\n",
      "226/226 [==============================] - 402s 2s/step - loss: 1.0174 - acc: 0.5983 - val_loss: 1.1879 - val_acc: 0.5534\n",
      "Epoch 16/30\n",
      "226/226 [==============================] - 401s 2s/step - loss: 0.9794 - acc: 0.6163 - val_loss: 1.1338 - val_acc: 0.5642\n",
      "Epoch 17/30\n",
      "226/226 [==============================] - 397s 2s/step - loss: 0.9397 - acc: 0.6309 - val_loss: 1.1022 - val_acc: 0.5650\n",
      "Epoch 18/30\n",
      "226/226 [==============================] - 406s 2s/step - loss: 0.9070 - acc: 0.6508 - val_loss: 1.0872 - val_acc: 0.5974\n",
      "Epoch 19/30\n",
      "226/226 [==============================] - 410s 2s/step - loss: 0.8719 - acc: 0.6609 - val_loss: 1.0558 - val_acc: 0.6015\n",
      "Epoch 20/30\n",
      "226/226 [==============================] - 415s 2s/step - loss: 0.8341 - acc: 0.6814 - val_loss: 1.1349 - val_acc: 0.5873\n",
      "Epoch 21/30\n",
      "226/226 [==============================] - 415s 2s/step - loss: 0.8104 - acc: 0.6931 - val_loss: 1.1148 - val_acc: 0.5978\n",
      "Epoch 22/30\n",
      "226/226 [==============================] - 417s 2s/step - loss: 0.7814 - acc: 0.7095 - val_loss: 1.0041 - val_acc: 0.6138\n",
      "Epoch 23/30\n",
      "226/226 [==============================] - 415s 2s/step - loss: 0.7566 - acc: 0.7208 - val_loss: 1.0027 - val_acc: 0.6309\n",
      "Epoch 24/30\n",
      "226/226 [==============================] - 416s 2s/step - loss: 0.7306 - acc: 0.7265 - val_loss: 0.9540 - val_acc: 0.6454\n",
      "Epoch 25/30\n",
      "226/226 [==============================] - 415s 2s/step - loss: 0.7015 - acc: 0.7344 - val_loss: 0.9834 - val_acc: 0.6317\n",
      "Epoch 26/30\n",
      "226/226 [==============================] - 418s 2s/step - loss: 0.6872 - acc: 0.7428 - val_loss: 0.9844 - val_acc: 0.6533\n",
      "Epoch 27/30\n",
      "226/226 [==============================] - 416s 2s/step - loss: 0.6544 - acc: 0.7542 - val_loss: 0.9981 - val_acc: 0.6447\n",
      "Epoch 28/30\n",
      "226/226 [==============================] - 412s 2s/step - loss: 0.6350 - acc: 0.7618 - val_loss: 0.9357 - val_acc: 0.6443\n",
      "Epoch 29/30\n",
      "226/226 [==============================] - 404s 2s/step - loss: 0.6179 - acc: 0.7701 - val_loss: 0.9949 - val_acc: 0.6488\n",
      "Epoch 30/30\n",
      "226/226 [==============================] - 400s 2s/step - loss: 0.5922 - acc: 0.7806 - val_loss: 0.9075 - val_acc: 0.6711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4456c59080>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trains the model for a given number of epochs (iterations on a dataset).\n",
    "model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=len(train_generator),\n",
    "                epochs=30,\n",
    "                verbose=1,\n",
    "                #callbacks= callbacks, #\n",
    "                validation_data=valid_generator,\n",
    "                validation_steps=len(valid_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kK1dEIP8nqWM"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "pic = cv2.imread('/content/gdrive/My Drive/train/backstrap/0.jpg',1)\n",
    "\n",
    "#cv2.imshow('shoes', pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "cOnVXwffmM-p",
    "outputId": "e4fa41fd-4142-4c9b-95a6-6c8ade2971ef"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('/content/My Drive/train/backstrap/0.jpg')\n",
    "\n",
    "## (1) Convert to gray, and threshold\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (2) Morph-op to remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "## (3) Find the max-area contour\n",
    "cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "## (4) Crop and save it\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "dst = img[y:y+h, x:x+w]\n",
    "cv2.imwrite(\"001.png\", dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1254
    },
    "colab_type": "code",
    "id": "tXNBqSZdX7QO",
    "outputId": "06a275a9-c136-48e7-f9e2-bb9d2af9898e"
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "QolQSAf1X7QR",
    "outputId": "40298c51-5173-475f-ded2-df9292ecf573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 220, 220, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 774400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               99123328  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 99,143,494\n",
      "Trainable params: 99,143,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvGYAFy_X7QU"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "yk-u5z_aWRx8",
    "outputId": "bece02d6-54d0-4035-9400-7dc615133022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jc3GDDkWgsP"
   },
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=20,\n",
    "    validation_split=0.2) # set validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ciYKA-AAfic-",
    "outputId": "f6a89223-64ae-4f26-e0e6-3851ed2941cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7854 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"/content/gdrive/My Drive/shoes_1/\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset='training') # set as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-RyP1q7egx1j",
    "outputId": "67f83530-8fb9-4ded-f53d-735f6dd853ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1961 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"/content/gdrive/My Drive/shoes_1/\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset='validation') # set as validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSkZoNyIjqoq"
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "KpfFvzq8kFE3",
    "outputId": "cb2478da-9bb5-4c09-e7b0-94fecf6b45d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "model =  VGG_16()\n",
    "opt = optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, decay=1e-5/5, amsgrad=False, clipnorm = 1.)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "# serialize model to JSON\n",
    "#print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGie7jyHkOTR"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1125
    },
    "colab_type": "code",
    "id": "DqZfZr7hkVmP",
    "outputId": "7bed34b1-9423-4732-e924-cc6c82a19253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "246/246 [==============================] - 3077s 13s/step - loss: 1.6994 - acc: 0.2635 - val_loss: 1.6538 - val_acc: 0.3304\n",
      "Epoch 2/30\n",
      "246/246 [==============================] - 300s 1s/step - loss: 1.5630 - acc: 0.3474 - val_loss: 1.4522 - val_acc: 0.4329\n",
      "Epoch 3/30\n",
      "246/246 [==============================] - 297s 1s/step - loss: 1.4395 - acc: 0.4129 - val_loss: 1.3891 - val_acc: 0.4615\n",
      "Epoch 4/30\n",
      "246/246 [==============================] - 297s 1s/step - loss: 1.3575 - acc: 0.4587 - val_loss: 1.3369 - val_acc: 0.4748\n",
      "Epoch 5/30\n",
      "246/246 [==============================] - 297s 1s/step - loss: 1.3348 - acc: 0.4658 - val_loss: 1.2723 - val_acc: 0.5038\n",
      "Epoch 6/30\n",
      "246/246 [==============================] - 298s 1s/step - loss: 1.2888 - acc: 0.4809 - val_loss: 1.2531 - val_acc: 0.5043\n",
      "Epoch 7/30\n",
      "246/246 [==============================] - 299s 1s/step - loss: 1.2748 - acc: 0.4883 - val_loss: 1.2687 - val_acc: 0.4911\n",
      "Epoch 8/30\n",
      "246/246 [==============================] - 298s 1s/step - loss: 1.2440 - acc: 0.4948 - val_loss: 1.2171 - val_acc: 0.5156\n",
      "Epoch 9/30\n",
      "246/246 [==============================] - 299s 1s/step - loss: 1.2337 - acc: 0.4935 - val_loss: 1.1714 - val_acc: 0.5477\n",
      "Epoch 10/30\n",
      "246/246 [==============================] - 307s 1s/step - loss: 1.1988 - acc: 0.5188 - val_loss: 1.1675 - val_acc: 0.5375\n",
      "Epoch 11/30\n",
      "246/246 [==============================] - 323s 1s/step - loss: 1.1850 - acc: 0.5193 - val_loss: 1.1364 - val_acc: 0.5579\n",
      "Epoch 12/30\n",
      "246/246 [==============================] - 325s 1s/step - loss: 1.1561 - acc: 0.5302 - val_loss: 1.1255 - val_acc: 0.5451\n",
      "Epoch 13/30\n",
      "246/246 [==============================] - 314s 1s/step - loss: 1.1387 - acc: 0.5370 - val_loss: 1.1033 - val_acc: 0.5665\n",
      "Epoch 14/30\n",
      "246/246 [==============================] - 324s 1s/step - loss: 1.1293 - acc: 0.5460 - val_loss: 1.0904 - val_acc: 0.5798\n",
      "Epoch 15/30\n",
      "246/246 [==============================] - 312s 1s/step - loss: 1.1012 - acc: 0.5572 - val_loss: 1.1470 - val_acc: 0.5472\n",
      "Epoch 16/30\n",
      "246/246 [==============================] - 309s 1s/step - loss: 1.0915 - acc: 0.5580 - val_loss: 1.0453 - val_acc: 0.5920\n",
      "Epoch 17/30\n",
      "246/246 [==============================] - 317s 1s/step - loss: 1.0833 - acc: 0.5661 - val_loss: 1.0533 - val_acc: 0.5910\n",
      "Epoch 18/30\n",
      "246/246 [==============================] - 319s 1s/step - loss: 1.0589 - acc: 0.5791 - val_loss: 1.0280 - val_acc: 0.5885\n",
      "Epoch 19/30\n",
      "246/246 [==============================] - 323s 1s/step - loss: 1.0588 - acc: 0.5804 - val_loss: 1.0982 - val_acc: 0.5767\n",
      "Epoch 20/30\n",
      "246/246 [==============================] - 302s 1s/step - loss: 1.0432 - acc: 0.5908 - val_loss: 1.0232 - val_acc: 0.6165\n",
      "Epoch 21/30\n",
      "246/246 [==============================] - 318s 1s/step - loss: 1.0231 - acc: 0.5959 - val_loss: 1.0212 - val_acc: 0.5992\n",
      "Epoch 22/30\n",
      "246/246 [==============================] - 304s 1s/step - loss: 1.0105 - acc: 0.5987 - val_loss: 1.0119 - val_acc: 0.6160\n",
      "Epoch 23/30\n",
      "246/246 [==============================] - 321s 1s/step - loss: 0.9996 - acc: 0.6133 - val_loss: 0.9877 - val_acc: 0.6288\n",
      "Epoch 24/30\n",
      "246/246 [==============================] - 325s 1s/step - loss: 0.9973 - acc: 0.6097 - val_loss: 0.9871 - val_acc: 0.6033\n",
      "Epoch 25/30\n",
      "246/246 [==============================] - 314s 1s/step - loss: 0.9745 - acc: 0.6166 - val_loss: 1.0181 - val_acc: 0.6160\n",
      "Epoch 26/30\n",
      "246/246 [==============================] - 312s 1s/step - loss: 0.9659 - acc: 0.6227 - val_loss: 0.9581 - val_acc: 0.6247\n",
      "Epoch 27/30\n",
      "246/246 [==============================] - 329s 1s/step - loss: 0.9487 - acc: 0.6288 - val_loss: 0.9698 - val_acc: 0.6379\n",
      "Epoch 28/30\n",
      "246/246 [==============================] - 314s 1s/step - loss: 0.9413 - acc: 0.6341 - val_loss: 0.9541 - val_acc: 0.6293\n",
      "Epoch 29/30\n",
      "246/246 [==============================] - 313s 1s/step - loss: 0.9285 - acc: 0.6378 - val_loss: 0.9161 - val_acc: 0.6568\n",
      "Epoch 30/30\n",
      "246/246 [==============================] - 299s 1s/step - loss: 0.9063 - acc: 0.6499 - val_loss: 0.8975 - val_acc: 0.6563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89fd92cf98>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = len(validation_generator),\n",
    "    epochs = 30,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1499
    },
    "colab_type": "code",
    "id": "E8uBH3OtO2FI",
    "outputId": "0ac7d2b2-95b0-4430-d1fd-a2adc684e7c4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "246/246 [==============================] - 329s 1s/step - loss: 1.6473 - acc: 0.2737 - val_loss: 1.6682 - val_acc: 0.3187\n",
      "Epoch 2/50\n",
      "246/246 [==============================] - 321s 1s/step - loss: 1.5448 - acc: 0.3383 - val_loss: 1.5234 - val_acc: 0.3646\n",
      "Epoch 3/50\n",
      "246/246 [==============================] - 331s 1s/step - loss: 1.4894 - acc: 0.3784 - val_loss: 1.4528 - val_acc: 0.3983\n",
      "Epoch 4/50\n",
      "246/246 [==============================] - 325s 1s/step - loss: 1.3928 - acc: 0.4324 - val_loss: 1.3471 - val_acc: 0.4646\n",
      "Epoch 5/50\n",
      "246/246 [==============================] - 320s 1s/step - loss: 1.3146 - acc: 0.4603 - val_loss: 1.3233 - val_acc: 0.4411\n",
      "Epoch 6/50\n",
      "246/246 [==============================] - 329s 1s/step - loss: 1.2351 - acc: 0.4960 - val_loss: 1.1826 - val_acc: 0.5181\n",
      "Epoch 7/50\n",
      "246/246 [==============================] - 326s 1s/step - loss: 1.1701 - acc: 0.5196 - val_loss: 1.1169 - val_acc: 0.5334\n",
      "Epoch 8/50\n",
      "246/246 [==============================] - 320s 1s/step - loss: 1.1163 - acc: 0.5477 - val_loss: 1.0421 - val_acc: 0.5798\n",
      "Epoch 9/50\n",
      "246/246 [==============================] - 329s 1s/step - loss: 1.0773 - acc: 0.5620 - val_loss: 1.1195 - val_acc: 0.5660\n",
      "Epoch 10/50\n",
      "246/246 [==============================] - 329s 1s/step - loss: 1.0352 - acc: 0.5846 - val_loss: 1.0278 - val_acc: 0.6017\n",
      "Epoch 11/50\n",
      "246/246 [==============================] - 328s 1s/step - loss: 1.0049 - acc: 0.5961 - val_loss: 0.9449 - val_acc: 0.6196\n",
      "Epoch 12/50\n",
      "246/246 [==============================] - 301s 1s/step - loss: 0.9707 - acc: 0.6194 - val_loss: 0.9416 - val_acc: 0.6395\n",
      "Epoch 13/50\n",
      "246/246 [==============================] - 300s 1s/step - loss: 0.9199 - acc: 0.6320 - val_loss: 0.8841 - val_acc: 0.6583\n",
      "Epoch 14/50\n",
      "246/246 [==============================] - 315s 1s/step - loss: 0.8928 - acc: 0.6520 - val_loss: 0.8615 - val_acc: 0.6655\n",
      "Epoch 15/50\n",
      "246/246 [==============================] - 312s 1s/step - loss: 0.8856 - acc: 0.6516 - val_loss: 0.9059 - val_acc: 0.6624\n",
      "Epoch 16/50\n",
      "246/246 [==============================] - 321s 1s/step - loss: 0.8500 - acc: 0.6679 - val_loss: 0.8523 - val_acc: 0.6675\n",
      "Epoch 17/50\n",
      "246/246 [==============================] - 313s 1s/step - loss: 0.8140 - acc: 0.6853 - val_loss: 0.8388 - val_acc: 0.6711\n",
      "Epoch 18/50\n",
      "246/246 [==============================] - 319s 1s/step - loss: 0.8039 - acc: 0.6897 - val_loss: 0.8072 - val_acc: 0.6884\n",
      "Epoch 19/50\n",
      "246/246 [==============================] - 315s 1s/step - loss: 0.7744 - acc: 0.6988 - val_loss: 0.8688 - val_acc: 0.6859\n",
      "Epoch 20/50\n",
      "246/246 [==============================] - 307s 1s/step - loss: 0.7735 - acc: 0.7056 - val_loss: 0.8532 - val_acc: 0.6813\n",
      "Epoch 21/50\n",
      "246/246 [==============================] - 304s 1s/step - loss: 0.7437 - acc: 0.7120 - val_loss: 0.7784 - val_acc: 0.6971\n",
      "Epoch 22/50\n",
      "246/246 [==============================] - 309s 1s/step - loss: 0.7292 - acc: 0.7182 - val_loss: 0.7490 - val_acc: 0.7088\n",
      "Epoch 23/50\n",
      "246/246 [==============================] - 302s 1s/step - loss: 0.7114 - acc: 0.7317 - val_loss: 0.7449 - val_acc: 0.7165\n",
      "Epoch 24/50\n",
      "246/246 [==============================] - 302s 1s/step - loss: 0.6941 - acc: 0.7343 - val_loss: 0.7165 - val_acc: 0.7226\n",
      "Epoch 25/50\n",
      "246/246 [==============================] - 316s 1s/step - loss: 0.6781 - acc: 0.7398 - val_loss: 0.7178 - val_acc: 0.7277\n",
      "Epoch 26/50\n",
      "246/246 [==============================] - 314s 1s/step - loss: 0.6576 - acc: 0.7501 - val_loss: 0.6868 - val_acc: 0.7343\n",
      "Epoch 27/50\n",
      "246/246 [==============================] - 299s 1s/step - loss: 0.6449 - acc: 0.7561 - val_loss: 0.6734 - val_acc: 0.7440\n",
      "Epoch 28/50\n",
      "246/246 [==============================] - 306s 1s/step - loss: 0.6208 - acc: 0.7652 - val_loss: 0.6757 - val_acc: 0.7404\n",
      "Epoch 29/50\n",
      "246/246 [==============================] - 304s 1s/step - loss: 0.6248 - acc: 0.7687 - val_loss: 0.6657 - val_acc: 0.7425\n",
      "Epoch 30/50\n",
      "246/246 [==============================] - 296s 1s/step - loss: 0.6052 - acc: 0.7715 - val_loss: 0.7512 - val_acc: 0.7364\n",
      "Epoch 31/50\n",
      "246/246 [==============================] - 297s 1s/step - loss: 0.5892 - acc: 0.7757 - val_loss: 0.7027 - val_acc: 0.7318\n",
      "Epoch 32/50\n",
      "246/246 [==============================] - 299s 1s/step - loss: 0.5886 - acc: 0.7760 - val_loss: 0.6454 - val_acc: 0.7578\n",
      "Epoch 33/50\n",
      "246/246 [==============================] - 297s 1s/step - loss: 0.5521 - acc: 0.7922 - val_loss: 0.6556 - val_acc: 0.7629\n",
      "Epoch 34/50\n",
      "246/246 [==============================] - 297s 1s/step - loss: 0.5367 - acc: 0.7971 - val_loss: 0.6462 - val_acc: 0.7608\n",
      "Epoch 35/50\n",
      "246/246 [==============================] - 296s 1s/step - loss: 0.5247 - acc: 0.8016 - val_loss: 0.7495 - val_acc: 0.7251\n",
      "Epoch 36/50\n",
      "246/246 [==============================] - 296s 1s/step - loss: 0.5279 - acc: 0.8046 - val_loss: 0.6343 - val_acc: 0.7598\n",
      "Epoch 37/50\n",
      "246/246 [==============================] - 297s 1s/step - loss: 0.5154 - acc: 0.8080 - val_loss: 0.6433 - val_acc: 0.7573\n",
      "Epoch 38/50\n",
      "246/246 [==============================] - 296s 1s/step - loss: 0.4864 - acc: 0.8199 - val_loss: 0.6707 - val_acc: 0.7761\n",
      "Epoch 39/50\n",
      "246/246 [==============================] - 297s 1s/step - loss: 0.4893 - acc: 0.8153 - val_loss: 0.6611 - val_acc: 0.7613\n",
      "Epoch 40/50\n",
      "246/246 [==============================] - 296s 1s/step - loss: 0.4667 - acc: 0.8241 - val_loss: 0.6742 - val_acc: 0.7471\n",
      "Epoch 41/50\n",
      "246/246 [==============================] - 315s 1s/step - loss: 0.4602 - acc: 0.8298 - val_loss: 0.6285 - val_acc: 0.7705\n",
      "Epoch 42/50\n",
      "246/246 [==============================] - 323s 1s/step - loss: 0.4400 - acc: 0.8395 - val_loss: 0.6566 - val_acc: 0.7664\n",
      "Epoch 43/50\n",
      " 22/246 [=>............................] - ETA: 3:56 - loss: 0.3865 - acc: 0.8537"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = len(validation_generator),\n",
    "    epochs = 50,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3-ba24tlLm6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_dataset.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
